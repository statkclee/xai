---
layout: page
title: "XAI"
subtitle: "설명가능한 AI (Explainable AI)"
author:
- name: "이광춘"
  affiliation: "[Tidyverse Korea](https://www.facebook.com/groups/tidyverse/)"
date: "`r Sys.Date()`"
tags: ["데이터 과학", "Data Science", "데이터 사이언스", "설명가능한 AI", "XAI", "Explainable AI"]
output:
  html_document: 
    include:
      after_body: footer.html
      before_body: header.html
    toc: yes
    toc_depth: 2
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
bibliography: bibliography_xai.bib
csl: biomed-central.csl
urlcolor: blue
linkcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```

# 알고리즘 &rarr; 데이터 [@Gianfagna2021] [@Biecek2021] [@rothman2020hands-on] {#algorithm-to-data}

과거 프로그램 규칙을 소프트웨어 엔지니어가 알고리즘을 통해서 작성했다면 인공지능 시대에는 기계가 스스로 데이터를 학습해서 작성하게 된다. 

![](fig/algorithm2data.png)

- **모형 검증(Model Validation)**: 어떤 분이 신용대출에서 배제된다면, 블랙박스 모형을 살펴보고 배제된 사유를 설명할 수 있어야 한다. 즉, 특정 사람을 인종이나 성별, 나이 등을 이유로 편향성(Bias)이 내재된 데이터를 기계가 학습했는지 살펴볼 필요가 있다. 법원 판결, 의료정보 등 민감정보에 대한 프라이버시도 필히 준수되어야 한다. 
- **모형 디버깅(Model Debugging)**: 신뢰성(Reliability)과 강건성(Robustness)가 보장되어 입력값의 작은 변화가 출력값의 큰 결과로 이어지면 되지 않는다. 투명성(Trasparency)과 해석가능성(Interpretability)도 블랙바스 모형이 오동작 혹은 납득되지 않는 예측값을 낳았을 때 모형 디버깅을 위해서 꼭 필요하다.
- **지식발견(Knowledge Discovery)**

# EDA vs EMA {#eda-vs-ema}

**탐색적 데이터 분석(Explanatory Data Analysis)**와 **탐색적 모형 분석(Explanatory Model Analysis)**을 비교해 보자.

![](fig/EDAvsEMA.png)

# XAI 작업흐름 {#xai-workflow}

과거 기계가 학습한 함수 즉, 기계학습 모형은 추천, 예측(prediction), 의사결정(classification) 결과값만을 사용자에게 전달하였다. 예측력이 좋아서 유용성은 인정받았지만 다음 질문에 대한 답을 제시하지 못한 아쉬움도 있다.

- AI가 왜 그렇게 동작하는가?
- 왜 다르게 동작하지는 않는가?
- 사용자가 언제 AI를 믿을 수 있을까?

하지만, XAI를 통하게 되면 기본적인 예측력에 대한 도움을 받을 수 있을 뿐만 아니라 다음 질문에 대해서는 도움을 받을 수가 있다.

- AI가 동작하는 이유를 이해한다.
- AI가 동작하지 않는 이유도 이해한다.
- 어느 시점에 AI를 믿어야할지 알게 된다.

XAI 작업흐름은 다음과 같은데, 설명가능한 모형을 만들어 인터페이스를 제작하여 또다른 형태의 객체(함수)를 만들어 기계가 학습한 모형(함수)에 대해 파악하게 된다.

![](fig/xai-workflow.png)

## 한걸음 더 들어감 {#move-step-forwards}

기계가 데이터를 통해 학습한 모형(함수)를 설명가능한 모형으로 살펴보는 접근 방법은 크게 두가지로 나뉜다. 하나는 모형에 독립적인 접근법(Agnostic Approach)과 모형 의존적인 접근방법(Model Dependent Approach)로 나뉘고 관측점 하나를 설명하느냐 전체를 설명하느냐에 따라 나뉜다. 하지만 설명가능한 인터페이스는 하나로 정리된다.


![](fig/xai-workflows-inside.png)

# EMA {#EMA}


